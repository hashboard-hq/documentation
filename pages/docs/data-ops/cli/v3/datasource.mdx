---
description: The databases command allows you to see a list of all available database connections when developing Hashboard resources via the CLI.
---

import { Callout, Steps } from "nextra-theme-docs";

# Hashboard `datasource` command

The `datasource` command allows to perform various functions related to your Hashhboard data sources.

### `hb datasource ls`
List all your existing data sources for a given project in Hashboard.

```bash copy
hb datasource ls

Successfully logged in to Pizza Bytes

üóí  Available data connections 
+--------------------------+----------------------+------------------+
| Data connection name     | Data connection type | ID               |
+--------------------------+----------------------+------------------+
| Snowflake db connection  | snowflake            | BNwVyrQ3FY4qejuU |
| Bigquery db connection   | big_query            | 92hu4Ff8QZ79JCNO |
| Databricks db connection | databricks           | 53FmRprC_7USlpn_ |
+--------------------------+----------------------+------------------+

```
You can explore data sources further using the [`tables`](./tables) command. 

To create data sources using the CLI, you can either upload files directly to Hashboard using the `datasource upload` command described below, or configure a connection to 
a data warehouse using the `datasource create` command described below.

Also see the [Hashboard guide](/docs/database-connections) for more information about connecting to your database.

### `hb datasource create`
A group of commands for creating Hashboard data sources.

Available subcommands:
- [Athena](/docs/database-connections/athena): `hb datasource create athena` 
- [BigQuery](/docs/database-connections/bigquery): `hb datasource create bigquery`
- [Clickhouse](/docs/database-connections/clickhouse): `hb datasource create clickhouse`
- [Databricks](/docs/database-connections/databricks): `hb datasource create databricks`
- [Motherduck](/docs/database-connections/motherduck): `hb datasource create motherduck`
- [MySQL](/docs/database-connections/mysql): `hb datasource create mysql`
- [PostgreSQL](/docs/database-connections/postgresql): `hb datasource create postgres`
- [Redshift](/docs/database-connections/redshift): `hb datasource create redshift`
- [Snowflake](/docs/database-connections/snowflake): `hb datasource create snowflake`

Each subcommand takes a set of arguments that are specific to the data source type. For more information, run `hb datasource create [data_source_type] --help`.

```bash copy
hb datasource create [data_source_type] [arguments...]
```

### `hb datasource update`
A group of commands for updating Hashboard data sources. The available subcommands are the same as in `hb datasource create`.

The arguments for each subcommand are specific to the data source type, and identical to the arguments required for `hb datasource create`, 
except for `id`, which is required for each data source type. To find the `id` of a data source, run `hb datasource ls`.

```bash copy
hb datasource create [data_source_type] [id] [arguments...]
```

### `hb datasource test`
Test an existing Hashboard data connection by providing its name.
```bash copy
hb datasource test bigquery_connection      

Successfully logged in to Pizza Bytes

üîç Testing connection to bigquery_connection...
üéâ Successfully connected to bigquery_connection.
```

### `hb datasource upload`
Upload files directly to Hashboard that can be queried using [DuckDB](/docs/database-connections/duckdb) and used as the
basis for a data model.

```bash copy
hb datasource upload [filepaths...]
```

Currently Hashboard supports uploading data as csv, tsv, json, or parquet files. These tables can be referenced when building out [model configurations](/docs/data-ops/config-schema/data-models).


